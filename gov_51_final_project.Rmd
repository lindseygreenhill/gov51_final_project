---
title: "gov_51_final_project"
author: "Owen Bernstein and Lindsey Greenhill"
date: "11/15/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Loading necessary packages

library(gt)
library(broom)
library(skimr)
library(lubridate)
library(janitor)
library(dotwhisker)
library(tidytext)
library(ggthemes)
library(webshot)
library(stargazer)
library(tidyverse)

```

```{r data loading, include = FALSE, eval=FALSE}

# Reading in the data and then using bind rows to combine the candidates'
# speeches.

data <- read_csv("data/10-17-10-23.csv") %>%
  bind_rows(read_csv("data/10-24-10-31.csv")) %>%
  bind_rows(read_csv("data/11-1-11-7.csv")) %>%
  bind_rows(read_csv("data/11-8-11-14.csv")) %>%
  clean_names() %>%
  filter(channel != "BBCNEWS") %>%
  mutate(ranking = if_else(channel == "FOXNEWSW",
                           1, if_else(channel == "CNNW", 2, 3)))

# Cleaning the speeches and counting the number of words while removing stop
# words.

tidy_data <- data %>% 
  clean_names() %>% 
  mutate(date = mdy_hm(date_time_utc)) %>%
  mutate(date_x = as.Date(substr(date, 1, 10))) %>%
  select(channel, text, ranking, date_x) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  group_by(channel, ranking, date_x, word) %>%
  count()



```

```{r basket of words, include = FALSE, eval=FALSE}

# Counting words by each differnet content category

populism <- tidy_data %>% 
  group_by(date_x, channel, ranking) %>% 
  filter(str_detect(word, "deceit") | str_detect(word, "treason")
         | str_detect(word, "betray") | str_detect(word, "absurd")
         | str_detect(word, "arrogant") | str_detect(word, "promise") 
         | str_detect(word, "corrupt") | str_detect(word, "direct")
         | str_detect(word, "elite") | str_detect(word, "establishment")
         | str_detect(word, "ruling") | str_detect(word, "caste")
         | str_detect(word, "class") | str_detect(word, "mafia")
         | str_detect(word, "freedom of expression")
         | str_detect(word, "undemocratic") | str_detect(word, "politic")
         | str_detect(word, "propaganda") | str_detect(word, "referend")
         | str_detect(word, "regime") | str_detect(word, "shame")
         | str_detect(word, "admit") | str_detect(word, "tradition")
         | str_detect(word, "people")) %>% 
  summarize(populism_count = sum(n)) %>% 
  arrange(desc(populism_count))

environment <- tidy_data %>% 
  group_by(date_x, channel, ranking) %>% 
  filter(str_detect(word, "green") | str_detect(word, "climate")
         | str_detect(word, "environment") | str_detect(word, "heating")
         | str_detect(word, "durable")) %>% 
  summarise(environment_count = sum(n)) %>% 
  arrange(desc(environment_count))

immigration <- tidy_data %>% 
  group_by(date_x, channel, ranking) %>% 
  filter(str_detect(word, "asylum") | str_detect(word, "halal")
         | str_detect(word, "scarf") | str_detect(word, "illegal")
         | str_detect(word, "immigra") | str_detect(word, "Islam") 
         | str_detect(word, "Koran") | str_detect(word, "Muslim")
         | str_detect(word, "foreign")) %>% 
  summarise(immigration_count = sum(n)) %>% 
  arrange(desc(immigration_count))

progressive <- tidy_data %>% 
  group_by(date_x, channel, ranking) %>% 
  filter(str_detect(word,"progress") | str_detect(word, "right")
         | str_detect(word, "freedom") | str_detect(word, "self-disposition")
         | str_detect(word, "handicap") | str_detect(word, "poverty") 
         | str_detect(word, "protection") | str_detect(word, "honest")
         | str_detect(word, "equal") | str_detect(word, "education")
         | str_detect(word, "pension") | str_detect(word, "social") 
         | str_detect(word, "weak")) %>% 
  summarise(progressive_count = sum(n)) %>% 
  arrange(desc(progressive_count))

conservatism <- tidy_data %>% 
  group_by(date_x, channel, ranking) %>%  
  filter(str_detect(word, "belief") | str_detect(word, "famil")
         | str_detect(word, "church") | str_detect(word, "norm")
         | str_detect(word, "porn") | str_detect(word, "sex")
         | str_detect(word, "values") | str_detect(word, "conservative")
         | str_detect(word, "conservatism") | str_detect(word, "custom")) %>% 
  summarise(conservatism_count = sum(n)) %>% 
  arrange(desc(conservatism_count))

# Combining each of the conent categories into a single data frame. Also adding
# party affiliations and percent values

sentiment_channels <- populism %>% 
  full_join(environment, by = c("date_x", "channel",
                                "ranking")) %>% 
  full_join(immigration, by = c("date_x", "channel",
                                "ranking")) %>% 
  full_join(progressive, by = c("date_x", "channel",
                                "ranking")) %>% 
  full_join(conservatism, by = c("date_x", "channel",
                                "ranking"))%>%
  select(date_x, channel, ranking, populism_count,
         environment_count, immigration_count, 
         progressive_count, conservatism_count) %>%
  ungroup() %>% 
  distinct()

save(sentiment_channels, file = "data/sentiment_channels.Rdata")
```


```{r making graphs, include = FALSE}

load("data/sentiment_channels.Rdata")

pop_time <- ggplot(sentiment_channels, aes(date_x, populism_count, color = channel)) +
  geom_jitter(alpha = 0.5, width = 100) +
  geom_smooth(method = "lm", se = F) +
  labs(title = "Populist Language in Presidential Speeches Over Time",
       x = "Date of Speech", y = "Percent Populist Language") +
  theme_minimal()


pop_hist <- sentiment_channels %>% 
  ggplot(., aes(channel, populism_count)) +
  geom_boxplot() + 
  labs(title = "Populist Language in Speeches by Channel",
       subtitle = "October 17 to November 14",
       x = "Channel", y = "Language Count") +
  theme_minimal() +
  theme(axis.line = element_line())

env_hist <- sentiment_channels %>% 
  ggplot(., aes(channel, environment_count)) +
  geom_boxplot() + 
  labs(title = "Environmental Language in Speeches by Channel",
       subtitle = "October 17 to November 14",
       x = "Channel", y = "Language Count") +
  theme_minimal() +
  theme(axis.line = element_line())

imm_hist <- sentiment_channels %>% 
  ggplot(., aes(channel, immigration_count)) +
  geom_boxplot() + 
  labs(title = "Immigration Language in Speeches by Channel",
       subtitle = "October 17 to November 14",
       x = "Channel", y = "Language Count") +
  theme_minimal() +
  theme(axis.line = element_line())

prog_hist <- sentiment_channels %>% 
  ggplot(., aes(channel, progressive_count)) +
  geom_boxplot() + 
  labs(title = "Progressivism Language in Speeches by Channel",
       subtitle = "October 17 to November 14",
       x = "Channel", y = "Language Count") +
  theme_minimal() +
  theme(axis.line = element_line())

cons_hist <- sentiment_channels %>% 
  ggplot(., aes(channel, conservatism_count)) +
  geom_boxplot() + 
  labs(title = "Conservatism Language in Speeches by Channel",
       subtitle = "October 17 to November 14",
       x = "Channel", y = "Language Count") +
  theme_minimal() +
  theme(axis.line = element_line())

language_all_counts <- sentiment_channels %>%
  pivot_longer(cols = populism_count:conservatism_count,
               names_to = "metric",
               values_to = "count") %>%
  ggplot(aes(x = date_x, y = count, color = channel)) +
  geom_point() +
  theme_classic() +
  facet_wrap(~metric) +
  labs(title = "Language Sentiment Across Channels",
       subtitle = "October 17 to November 14",
       x = "Date",
       y = "Word Count")

sum_table <- sentiment_channels %>% group_by(channel) %>%
  summarize(total_populism = sum(populism_count),
            total_environment = sum(environment_count, na.rm = T),
            total_immigration = sum(immigration_count, na.rm = T),
            total_proggresivsim = sum(progressive_count, na.rm = T),
            total_conservatism = sum(conservatism_count, na.rm = T),
            .groups = "drop")

summ_table_gt <- sum_table %>%
  gt() %>%
  tab_header(title = "Language Sentiment Across Channels",
             subtitle = "October 17 to November 14")



```


```{r regression, include = FALSE}

sentiment_channels

populist_fit <- lm(populism_count ~ ranking, data = sentiment_channels)
immigration_fit <- lm(immigration_count ~ ranking, data = sentiment_channels)
env_fit <- lm(environment_count ~ ranking, data = sentiment_channels)
prog_fit <- lm(progressive_count ~ ranking, data = sentiment_channels)
cons_fit <- lm(conservatism_count ~ ranking, data = sentiment_channels)


reg_plots <- sentiment_channels %>%
  pivot_longer(cols = populism_count:conservatism_count,
               names_to = "metric",
               values_to = "count") %>%
  ggplot(aes(x = ranking, y = count)) +
  geom_jitter(width = .2) +
  geom_smooth(method = "lm") +
  facet_wrap(~metric) +
  theme_classic() +
  labs(title = "Language Count vs. Channel Ranking",
       x = "Channel Ideology Ranking",
       y = "Count")


```
## Preliminary Analysis

In this analysis, we gathered, cleaned, and wrangled news data from October 17 to November 14, 2020. 
We chose to include Fox News, CNN, and MSNB in our analysis and assigned those channels ideological
rankings of 1, 2, and 3, respectively. The plots below show our preliminary findings.

### How much specific language is each channel using?

We classified the below categories using word baskets built by the study referenced in our project proposal. The table below shows the raw counts of how many times each channel used a word associated with these categories. 

```{r gt, echo=FALSE}
summ_table_gt
```

### How much specific language is each channel using each day?

The histograms below visualize how much channels use the categorical language on a daily basis. 

```{r hists, warning = FALSE, echo=FALSE}
pop_hist
env_hist
imm_hist
prog_hist
cons_hist

```

### How does usage vary across time?

The plots below visualize the change in daily language use for each channel.

```{r time, echo=FALSE, warning=FALSE}
language_all_counts
```

### Regression: Does Ideology have an affect on language usage?

The table below shows the results of five different regressions and the plot below shows the line of best fit for each regression. 

```{r regs, results = "asis", echo=FALSE, warning=FALSE}
stargazer(populist_fit, immigration_fit,
          env_fit,
          prog_fit,
          cons_fit,
          type = "latex")
reg_plots



```

There does not appear to be a strong relationship between ideology and language usage. 


